{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "### Idea \n",
    "\n",
    "Train a classification model using human radiograph images. We will then use class activation mapping to extract heatmaps to help localize any lesions.\n",
    "\n",
    "For the dataset, labels were extracted from the radiologist report where: blank for unmentioned, 0 for negative, -1 for uncertain, and 1 for positive. See [here](https://stanfordmlgroup.github.io/competitions/chexpert/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from data_preparation import prepare_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below can be used to verify that the gpu is in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET_HEIGHT = 640\n",
    "TARGET_WIDTH = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, train_labels_df, targets = prepare_data(split='train')\n",
    "X_val, y_val, valid_labels_df, _ = prepare_data(split='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexnet_targets = ['No Finding',\n",
    "       'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "       'Support Devices']\n",
    "\n",
    "chexpert_targets = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty Approaches\n",
    "The CheXpert paper outlines several different approaches to mapping using the uncertainty labels in the data:\n",
    "\n",
    "- Ignoring - essentially removing from the calculation in the loss function\n",
    "- Binary mapping - sending uncertain values to either 0 or 1\n",
    "- Prevalence mapping - use the rate of prevelance of the feature as it's target value\n",
    "- Self-training - consider the uncertain values as unlabeled\n",
    "- 3-Class Classification - retain a separate value for uncertain and try to predict it as a class in its own right\n",
    "\n",
    "The paper gives the results of different experiments with the above approaches and indicates the most accurate approach for each feature.\n",
    "    \n",
    "|Approach/Feature|Atelectasis|Cardiomegaly|Consolidation|Edema|PleuralEffusion|\n",
    "|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "|`U-Ignore`|0.818(0.759,0.877)|0.828(0.769,0.888)|0.938(0.905,0.970)|0.934(0.893,0.975)|0.928(0.894,0.962)|\n",
    "|`U-Zeros`|0.811(0.751,0.872)|0.840(0.783,0.897)|0.932(0.898,0.966)|0.929(0.888,0.970)|0.931(0.897,0.965)|\n",
    "|`U-Ones`|**0.858(0.806,0.910)**|0.832(0.773,0.890)|0.899(0.854,0.944)|0.941(0.903,0.980)|0.934(0.901,0.967)|\n",
    "|`U-Mean`|0.821(0.762,0.879)|0.832(0.771,0.892)|0.937(0.905,0.969)|0.939(0.902,0.975)|0.930(0.896,0.965)|\n",
    "|`U-SelfTrained`|0.833(0.776,0.890)|0.831(0.770,0.891)|0.939(0.908,0.971)|0.935(0.896,0.974)|0.932(0.899,0.966)|\n",
    "|`U-MultiClass`|0.821(0.763,0.879)|**0.854(0.800,0.909)**|0.937(0.905,0.969)|0.928(0.887,0.968)|0.936(0.904,0.967)|\n",
    "\n",
    "The binary mapping approaches (U-Ones and U-Zeros) are easiest to implement and so to begin with we take the best option between U-Ones and U-Zeros for each feature\n",
    "\n",
    "- Atelectasis `U-Ones`\n",
    "- Cardiomegaly `U-Zeros`\n",
    "- Consolidation `U-Zeros`\n",
    "- Edema `U-Ones`\n",
    "- Pleural Effusion `U-Zeros`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df['valid'] = False\n",
    "valid_labels_df['valid'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_labels_df, valid_labels_df], ignore_index=True)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View a sample of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the first 5 images\n",
    "paths =  full_df.path[:5]\n",
    "labels = full_df.feature_string[:5]\n",
    "\n",
    "fig, m_axs = plt.subplots(1, len(labels), figsize = (20, 10))\n",
    "#show the images and label them\n",
    "for ii, c_ax in enumerate(m_axs):\n",
    "    c_ax.imshow(np.asarray(Image.open(paths[ii])), cmap='gray')\n",
    "    c_ax.set_title(labels[ii])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = np.asarray(Image.open(X_val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.stack((img,)*3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "ax.imshow(img)\n",
    "ax.axis('off')\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Image\n",
    "\n",
    "Most of the models test here are convolutional neural networks which have built-in translational equivariance as a result of the action of convolutional filters on the underlying image. This results in the classifier being translation invariant. However translation invariance is not the only invariance we would like our model to have, and for this reason it's important to have a large representative dataset so that many other invariances can be learned by the model during training. Augmentation is another way for us to help the model learn other invariances such as changes in brightness, saturation, contrast, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_mask(image, size=12, n_squares=1):\n",
    "    h, w, channels = image.shape\n",
    "    new_image = np.asarray(image.copy())\n",
    "    for _ in range(n_squares):\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "        y1 = np.clip(y - size // 2, 0, h)\n",
    "        y2 = np.clip(y + size // 2, 0, h)\n",
    "        x1 = np.clip(x - size // 2, 0, w)\n",
    "        x2 = np.clip(x + size // 2, 0, w)\n",
    "        new_image[y1:y2, x1:x2, :] = 0\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if np.random.uniform() < 0.5:\n",
    "    augmented = apply_mask(img, size=np.random.randint(low=70, high=240), n_squares=np.random.randint(low=2, high=12))\n",
    "else:\n",
    "    augmented = tf.image.random_brightness(img, max_delta=0.2)\n",
    "    augmented = tf.image.random_saturation(image=augmented, lower=0.8, upper=1.2)\n",
    "    augmented = tf.image.random_hue(image=augmented, max_delta=0.03)\n",
    "    augmented = tf.image.random_contrast(image=augmented, lower=0.8, upper=1.2)\n",
    "# augmented = tf.image.random_flip_up_down(img)\n",
    "# augmented = tf.image.random_flip_left_right(img)\n",
    "# augmented = tf.image.random_saturation(image=img, lower=0.7, upper=1.3)\n",
    "# augmented = tf.image.random_hue(image=img, max_delta=0.03)\n",
    "# augmented = tf.image.random_contrast(image=img, lower=0.7, upper=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "ax.imshow(augmented, cmap='gray')\n",
    "ax.axis('off')\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN = len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine class weights\n",
    "\n",
    "We often need to deal with an imbalance of classes in our dataset, especially if we want to get good recall on under represented classes. One way to do that is by using class weights so that a relatively higher loss is given on misclassifications of the under represented classes. The amount of class weighting, between none and emulating a uniform distribution, depends on the tradeoff between precision and recall for the classes. For this we will use log-scaled class weighting which will make a relatively slight adjustment toward a more uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = [col_name + '_label' for col_name in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=target_columns, height=y_train.sum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = y_train.sum(axis=0)\n",
    "total_count = y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_weights = {i: total_count/class_i_count for i, class_i_count in enumerate(class_counts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_weights_sqrt = {i: np.sqrt(weight) for i, weight in enumerate(list(cls_weights.values()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_weights_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_weights_log = {i: np.log(weight) for i, weight in enumerate(list(cls_weights.values()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_weights_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_weighted = y_train * np.array(list(cls_weights.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=target_columns, height=y_train_weighted.sum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_weighted_sqrt = y_train * np.array(list(cls_weights_sqrt.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=target_columns, height=y_train_weighted_sqrt.sum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_weighted_log = y_train * np.array(list(cls_weights_log.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=target_columns, height=y_train_weighted_log.sum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_CLASS_WEIGHTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_CLASS_WEIGHTS:\n",
    "    CLASS_WEIGHTS = cls_weights_log\n",
    "else:\n",
    "    CLASS_WEIGHTS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_image_to_array(path):\n",
    "    img = np.asarray(Image.open(path), dtype=np.float32)\n",
    "    img = np.stack((img,)*3, axis=-1)\n",
    "    img /= 255.\n",
    "    img = tf.image.resize_with_pad(img, target_height=TARGET_HEIGHT, target_width=TARGET_WIDTH)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_file(X_path, y):\n",
    "    \"\"\"\n",
    "    X_path: (pandas series) contains the file paths to the images\n",
    "    y: (pandas series of type int) the target label\n",
    "    \n",
    "    return a pair of numpy arrays representing (features, target)\n",
    "    \"\"\"\n",
    "    \n",
    "    X = pd.Series(X_path).apply(convert_image_to_array)\n",
    "    X = X.values\n",
    "    X = list(X)\n",
    "    X = np.array(X, dtype='float32')\n",
    "    \n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_predict(path, model):\n",
    "    x = convert_image_to_array(path=path)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data = create_model_file(X_path=X_val, y=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image.fromarray(np.uint8(255 * val_data[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img_path, target_image_size, dtype, scale_image):\n",
    "    # read the image\n",
    "    img = np.asarray(Image.open(img_path), dtype=dtype)\n",
    "    img = np.stack((img,)*3, axis=-1)\n",
    "\n",
    "    # add image augmentation\n",
    "    if np.random.uniform() < 0.5:\n",
    "        img = apply_mask(img, size=np.random.randint(low=70, high=240), n_squares=np.random.randint(low=2, high=12))\n",
    "    else:\n",
    "        if np.random.uniform() < 0.15:\n",
    "            img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "        if np.random.uniform() < 0.15:\n",
    "            img = tf.image.random_saturation(image=img, lower=0.8, upper=1.2)\n",
    "        if np.random.uniform() < 0.15:\n",
    "            img = tf.image.random_hue(image=img, max_delta=0.03)\n",
    "        if np.random.uniform() < 0.15:\n",
    "            img = tf.image.random_contrast(image=img, lower=0.8, upper=1.2)\n",
    "\n",
    "    if scale_image:\n",
    "        img = img/255.\n",
    "\n",
    "    # resize image\n",
    "    img = tf.image.resize_with_pad(img, target_height=target_image_size[0], target_width=target_image_size[1])\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize some transformed images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = X_val[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = transform_image(img_path=img_path, target_image_size=(TARGET_HEIGHT, TARGET_WIDTH), dtype=np.float32, scale_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(np.uint8(255 * img.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_gen(X, y, batch_size, image_size=(TARGET_HEIGHT, TARGET_WIDTH), dtype=np.float32, scale_image=True):\n",
    "    # Get total number of samples in the data\n",
    "    n = len(X)\n",
    "    steps = n//batch_size\n",
    "    \n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, image_size[0], image_size[1], 3), dtype=dtype)\n",
    "    batch_labels = np.zeros((batch_size, num_classes), dtype=dtype)\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "    \n",
    "    # Initialize a counter\n",
    "    i = 0\n",
    "    while True:\n",
    "        np.random.shuffle(indices)\n",
    "        # Get the next batch \n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_path = X[idx]\n",
    "            label = y[idx]\n",
    "            \n",
    "            # one hot encoding\n",
    "            encoded_label = label\n",
    "            \n",
    "            # Transform/augment the image\n",
    "            img = transform_image(img_path=img_path, target_image_size=image_size, dtype=dtype, scale_image=scale_image)\n",
    "            \n",
    "            batch_data[count] = img\n",
    "            batch_labels[count] = encoded_label\n",
    "\n",
    "            count+=1\n",
    "\n",
    "            if count==batch_size:\n",
    "                break\n",
    "            \n",
    "        i+=1\n",
    "        yield batch_data, batch_labels\n",
    "            \n",
    "        if i>=steps:\n",
    "            i=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Utility Functions\n",
    "\n",
    "Define some functions that will help simplify the fine-tuning pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def freeze_layers(model, freeze_layer_name):\n",
    "    for layer in model.layers:\n",
    "        if layer.name != freeze_layer_name:\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "            break\n",
    "            \n",
    "def unfreeze_batch_norm(model):\n",
    "    for layer in model.layers:\n",
    "        if layer.__class__.__name__ == 'BatchNormalization':\n",
    "            layer.trainable = True\n",
    "            \n",
    "def unfreeze_layer_norm(model):\n",
    "    for layer in model.layers:\n",
    "        if layer.__class__.__name__ == 'LayerNormalization':\n",
    "            layer.trainable = True\n",
    "\n",
    "def print_layer_trainable(model):\n",
    "    for layer in model.layers:\n",
    "        print('{0}:\\t{1}'.format(layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.convnext import LayerScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all models\n",
    "!ls ../models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'pretrain_model_ConvNeXtBase_w_ClssWgt_02-0.4721.h5'\n",
    "model_path = f'../models/{MODEL_NAME}'\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={'LayerScale': LayerScale})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer_trainable(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "TODO Add in MobileNetV2, EfficientNet (this requires tensorflow 2.2 nightly update import once this is in stable release), DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.xception import Xception\n",
    "\n",
    "# input_tensor = layers.Input(shape=(450, 600, 3), name='ImageInput')\n",
    "\n",
    "# model = Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: Expected input from B5, B6, B7 are 456x456, 528x528, 600x600\n",
    "# from tensorflow.python.keras.applications.efficientnet import EfficientNetB6\n",
    "\n",
    "# input_tensor = layers.Input(shape=(TARGET_HEIGHT, TARGET_WIDTH, 3), name='ImageInput')\n",
    "\n",
    "# model = EfficientNetB6(include_top=False, weights='imagenet', input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n",
    "\n",
    "# input_tensor = layers.Input(shape=(TARGET_HEIGHT, TARGET_WIDTH, 3), name='ImageInput')\n",
    "\n",
    "# model = ResNet101V2(include_top=False, weights='imagenet', input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.densenet import DenseNet201\n",
    "\n",
    "# input_tensor = layers.Input(shape=(TARGET_HEIGHT, TARGET_WIDTH, 3), name='ImageInput')\n",
    "\n",
    "# model = DenseNet201(include_top=False, weights='imagenet', input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import ConvNeXtSmall\n",
    "\n",
    "# input_tensor = layers.Input(shape=(TARGET_HEIGHT, TARGET_WIDTH, 3), name='ImageInput')\n",
    "\n",
    "# model = ConvNeXtSmall(include_top=False, weights='imagenet', input_tensor=input_tensor, include_preprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ConvNeXtBase\n",
    "\n",
    "input_tensor = layers.Input(shape=(TARGET_HEIGHT, TARGET_WIDTH, 3), name='ImageInput')\n",
    "\n",
    "model = ConvNeXtBase(include_top=False, weights='imagenet', input_tensor=input_tensor, include_preprocessing=False)\n",
    "# model = ConvNeXtBase(include_top=False, weights='imagenet', input_tensor=input_tensor, include_preprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine where to freeze and cut off base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: these were used to train Xception\n",
    "# transfer_layer_name = 'block14_sepconv1_act'\n",
    "# freeze_layer_name = 'add_10'\n",
    "\n",
    "# transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: these were used to train EfficientNet\n",
    "# transfer_layer_name = 'block7c_add'\n",
    "# freeze_layer_name = 'block6k_add'\n",
    "\n",
    "# transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: these were used to train ResNet101V2\n",
    "# transfer_layer_name = 'post_relu'\n",
    "# freeze_layer_name = 'conv5_block1_out'\n",
    "\n",
    "# transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: these were used to train DenseNet201\n",
    "# transfer_layer_name = 'relu'\n",
    "# # freeze_layer_name = 'conv5_block27_concat'\n",
    "\n",
    "# transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Note: these were used to train ConvNeXtSmall\n",
    "# transfer_layer_name = 'layer_normalization'\n",
    "# freeze_layer_name = 'tf.__operators__.add_33'\n",
    "\n",
    "# transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Note: these were used to train ConvNeXtBase\n",
    "# Idea: fine tune the last few layers, then retrain with entire model unfrozen\n",
    "transfer_layer_name = 'layer_normalization'\n",
    "freeze_layer_name = 'layer_normalization'\n",
    "# freeze_layer_name = 'tf.__operators__.add_21' # tf.__operators__.add_17, tf.__operators__.add_21, tf.__operators__.add_26, tf.__operators__.add_31\n",
    "# consider using smaller input image 512 x 512 and retrain more \n",
    "transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_model = tf.keras.Model(inputs=model.input, outputs=transfer_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(base_model, num_classes, pooling='avg', final_conv_layer='vgg_separable', expand_model=True, dropout_rate=0):\n",
    "    # Get the output of the base model on which we will build\n",
    "    x = base_model.layers[-1].output\n",
    "    \n",
    "    if expand_model:\n",
    "        if final_conv_layer == 'xception':\n",
    "            x = layers.SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_sepconv2')(x)\n",
    "            x = layers.BatchNormalization(name='block14_sepconv2_bn')(x)\n",
    "            x = layers.Activation('relu', name='block14_sepconv2_act')(x)\n",
    "        elif final_conv_layer == 'non_separable':\n",
    "            x = layers.Conv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_conv2')(x)\n",
    "            x = layers.BatchNormalization(name='block14_conv2_bn')(x)\n",
    "            x = layers.Activation('relu', name='block14_conv2_act')(x)\n",
    "        elif final_conv_layer == 'vgg_separable':\n",
    "            x = layers.SeparableConv2D(2048, (3,3), activation='relu', padding='same', name='block14_sepconv2')(x)\n",
    "        elif final_conv_layer == 'vgg':\n",
    "            x = layers.Conv2D(2048, (3,3), activation='relu', padding='same', name='block14_sepconv2')(x)\n",
    "        else:\n",
    "            raise ValueError('`final_conv_layer` should be one of the following: xception, non_separable, vgg_separable, or vgg')\n",
    "\n",
    "    if pooling == 'global_avg':\n",
    "        x = layers.GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    elif pooling == 'global_max':\n",
    "        x = layers.GlobalMaxPooling2D(name='global_max_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = layers.MaxPooling2D((2,2), name='local_max_pool')(x)\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "    elif pooling == 'avg':\n",
    "        x = layers.AveragePooling2D((2,2), name='local_avg_pool')(x)\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "    else:\n",
    "        pass\n",
    "    x = keras.layers.Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x = layers.Dense(num_classes, activation='sigmoid', name='prediction')(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = tf.keras.Model(base_model.input, x, name='Xception')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine good starting learning rate\n",
    "\n",
    "Experiment with the proper learning rate range by starting at a low number, see how many epochs for loss to get to a certain value, incrementally increase until the learning rate is too high. Use this range to determine the initial learning rate.\n",
    "\n",
    "Create a function to do this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_model = ConvNeXtBase(include_top=False, weights='imagenet', input_tensor=input_tensor, include_preprocessing=True)\n",
    "# local_conv_model = tf.keras.Model(inputs=local_model.input, outputs=local_model.output)\n",
    "\n",
    "# model_lr = build_model(base_model=local_conv_model, num_classes=num_classes, dropout_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_learning_rate(model, X, y, batch_size: int, lr_list: List[float], steps: int):\n",
    "    train_loss_by_lr = []\n",
    "    \n",
    "    for i, lr in enumerate(lr_list):\n",
    "        print(f'Learning rate {i + 1} of {len(lr_list)}. LR value: {lr}')\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        \n",
    "        hist = model.fit(\n",
    "            x=data_gen(X=X, y=y, batch_size=batch_size, scale_image=True), \n",
    "            epochs=1, \n",
    "            steps_per_epoch=steps,\n",
    "            class_weight=CLASS_WEIGHTS,\n",
    "        )\n",
    "        \n",
    "        final_loss = hist.history['loss'][-1]\n",
    "        final_acc = hist.history['accuracy'][-1]\n",
    "        \n",
    "        train_loss_by_lr.append((lr, final_loss, final_acc))\n",
    "      \n",
    "    losses_df = pd.DataFrame(train_loss_by_lr, columns=['learning_rate', 'training_loss', 'training_accuracy'])\n",
    "    \n",
    "    return losses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_loss_df = determine_learning_rate(model=model,\n",
    "                                     X=X_train, \n",
    "                                     y=y_train, \n",
    "                                     batch_size=2, \n",
    "                                     lr_list=[1e-1, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6, 1e-6, 1e-7, 1e-8,],\n",
    "                                     steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=lr_loss_df['learning_rate'].values, y=lr_loss_df['training_loss'].values)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ideally retrain the entire model, but memory is constrained \n",
    "freeze_layers(conv_model, freeze_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_model(base_model=conv_model, num_classes=num_classes, dropout_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unfreeze_batch_norm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unfreeze_layer_norm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_layer_trainable(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Model (alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path='./serialized_models/pretrain_model_ConvNeXtBase_w_ClssWgt_01-0.3887.h5'\n",
    "# model_path='./serialized_models/pretrain_model_ConvNeXtBase_w_ClssWgt_01-0.4021.h5'\n",
    "# model_path='./serialized_models/pretrain_model_ConvNeXtSmall_w_ClssWgt_03-0.5216.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.convnext import LayerScale\n",
    "# model = tf.keras.models.load_model(model_path, custom_objects={'LayerScale': LayerScale})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer_trainable(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Train on small sample\n",
    "\n",
    "The idea here is to train the model on a very small sample of the data as a kind of quality check so that even if it's overfitting we ensure that the model can learn the data and there's not some issue with our training/data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule_sample = keras.optimizers.schedules.CosineDecayRestarts(\n",
    "      initial_learning_rate=3e-4,\n",
    "      first_decay_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample = X_train[:20]\n",
    "y_train_sample = y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_sample = 100\n",
    "batch_size_sample = 4\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule_sample),\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    x=data_gen(X=X_train_sample, y=y_train_sample, batch_size=batch_size_sample, scale_image=True), \n",
    "    epochs=epochs_sample, \n",
    "#     validation_data=val_data, \n",
    "    steps_per_epoch=int(40/batch_size_sample),\n",
    "    class_weight=CLASS_WEIGHTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpLearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, warmup_epochs, init_lr, verbose=0):\n",
    "        \"\"\"\n",
    "        Constructor for the class.\n",
    "        :param warmup_epochs {int}: Number of epoch for which learning rate will be increased linearly.\n",
    "        :param init_lr {float}: Initial learning rate during warmup phase.\n",
    "        :param verbose {int}: 0: quiet, 1: update messages.\n",
    "        \"\"\"\n",
    "        super(WarmUpLearningRateScheduler, self).__init__()\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.init_lr = init_lr\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch+1 <= self.warmup_epochs:\n",
    "            lr = self.init_lr * (epoch+1) / self.warmup_epochs\n",
    "            tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "            if self.verbose > 0:\n",
    "                print('\\nEpoch %05d: WarmUpLearningRateScheduler setting learning '\n",
    "                      'rate to %s.' % (epoch + 1, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.CosineDecayRestarts(\n",
    "#       initial_learning_rate=3e-3,\n",
    "      initial_learning_rate=3e-4,\n",
    "      first_decay_steps=7979)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through cosine decay with restarts 7 times per epoch\n",
    "7979 == 55853 / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 4\n",
    "model_path='../models/pretrain_model_ConvNeXtBase_w_ClssWgt_{epoch:02d}-{val_loss:.4f}.h5'\n",
    "\n",
    "callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint(filepath=model_path, save_best_only=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=model_path),\n",
    "#     tf.keras.callbacks.ReduceLROnPlateau(patience=3),\n",
    "#     tf.keras.callbacks.EarlyStopping(patience=10),\n",
    "#     WarmUpLearningRateScheduler(warmup_epochs=3, init_lr=1e-5)\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    x=data_gen(X=X_train, y=y_train, batch_size=batch_size, scale_image=True), \n",
    "    epochs=epochs, \n",
    "    callbacks=callbacks, \n",
    "    validation_data=val_data, \n",
    "    steps_per_epoch=int(NUM_TRAIN/batch_size),\n",
    "    class_weight=CLASS_WEIGHTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Epoch 1\n",
    "- Starting point: loss: 0.75, accuracy 0.25\n",
    "- 1700/55853: loss: 0.74, accuracy 0.1625\n",
    "- 9600/55853: loss: 0.717, accuracy 0.2226\n",
    "- 18000/55853: loss: 0.699, accuracy 0.2762\n",
    "- 37000/55853: loss: 0.683, accuracy 0.3229\n",
    "- 46500/55853: loss: 0.674, accuracy 0.3385\n",
    "- 54000/55853: loss: 0.668, accuracy 0.3492\n",
    "------------------------------------\n",
    "- Epoch 2\n",
    "- 1000/55853: loss: 0.639, accuracy 0.402"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13300/55853, loss: 0.3006, accuracy: 0.2011\n",
    "7364/55853, loss: 1.2744, accuracy: 0.0874 (using built-in preprocessing rather than scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save final model - Make sure name is correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('./serialized_models/pretrain_model_ConvNeXtBase_w_ClssWgt_04-0.4061.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
