{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Pre Training\n",
    "\n",
    "### Idea \n",
    "\n",
    "Train a classification model using human radiograph images, and then fine tune on veterinary medical images\n",
    "\n",
    "For the dataset, labels were extracted from the radiologist report where: blank for unmentioned, 0 for negative, -1 for uncertain, and 1 for positive. See [here](https://stanfordmlgroup.github.io/competitions/chexpert/)\n",
    "\n",
    "### TODO \n",
    "\n",
    "- X Add learning rate scheduler to training. See keras options, and [this](https://www.jeremyjordan.me/nn-learning-rate/) blog post.\n",
    "- X Add performance analysis\n",
    "- X Add cutout augmentation as *last* augmentation. Do this in the other training notebook as well\n",
    "- X Add class weights\n",
    "- Add Lion optimizer\n",
    "- Add error analysis\n",
    "- Add k-fold cross validation\n",
    "- See what happens if a portion of the model is frozen (e.g. freeze the weights half way through)\n",
    "- Get heatmap piece at end working, so that you can visualize the argmax class of an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET_HEIGHT = 640\n",
    "TARGET_WIDTH = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_directory = '/data/CheXpert-v1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_folder = os.path.join(root_directory, 'train')\n",
    "valid_folder = os.path.join(root_directory, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels_df = pd.read_csv(os.path.join(root_directory, 'train.csv'))\n",
    "valid_labels_df = pd.read_csv(os.path.join(root_directory, 'valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexnet_targets = ['No Finding',\n",
    "       'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "       'Support Devices']\n",
    "\n",
    "chexpert_targets = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty Approaches\n",
    "The CheXpert paper outlines several different approaches to mapping using the uncertainty labels in the data:\n",
    "\n",
    "- Ignoring - essentially removing from the calculation in the loss function\n",
    "- Binary mapping - sending uncertain values to either 0 or 1\n",
    "- Prevalence mapping - use the rate of prevelance of the feature as it's target value\n",
    "- Self-training - consider the uncertain values as unlabeled\n",
    "- 3-Class Classification - retain a separate value for uncertain and try to predict it as a class in its own right\n",
    "\n",
    "The paper gives the results of different experiments with the above approaches and indicates the most accurate approach for each feature.\n",
    "    \n",
    "|Approach/Feature|Atelectasis|Cardiomegaly|Consolidation|Edema|PleuralEffusion|\n",
    "|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "|`U-Ignore`|0.818(0.759,0.877)|0.828(0.769,0.888)|0.938(0.905,0.970)|0.934(0.893,0.975)|0.928(0.894,0.962)|\n",
    "|`U-Zeros`|0.811(0.751,0.872)|0.840(0.783,0.897)|0.932(0.898,0.966)|0.929(0.888,0.970)|0.931(0.897,0.965)|\n",
    "|`U-Ones`|**0.858(0.806,0.910)**|0.832(0.773,0.890)|0.899(0.854,0.944)|0.941(0.903,0.980)|0.934(0.901,0.967)|\n",
    "|`U-Mean`|0.821(0.762,0.879)|0.832(0.771,0.892)|0.937(0.905,0.969)|0.939(0.902,0.975)|0.930(0.896,0.965)|\n",
    "|`U-SelfTrained`|0.833(0.776,0.890)|0.831(0.770,0.891)|0.939(0.908,0.971)|0.935(0.896,0.974)|0.932(0.899,0.966)|\n",
    "|`U-MultiClass`|0.821(0.763,0.879)|**0.854(0.800,0.909)**|0.937(0.905,0.969)|0.928(0.887,0.968)|0.936(0.904,0.967)|\n",
    "\n",
    "The binary mapping approaches (U-Ones and U-Zeros) are easiest to implement and so to begin with we take the best option between U-Ones and U-Zeros for each feature\n",
    "\n",
    "- Atelectasis `U-Ones`\n",
    "- Cardiomegaly `U-Zeros`\n",
    "- Consolidation `U-Zeros`\n",
    "- Edema `U-Ones`\n",
    "- Pleural Effusion `U-Zeros`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old approach\n",
    "\n",
    "# u_one_features = ['Atelectasis', 'Edema']\n",
    "# u_zero_features = ['Cardiomegaly', 'Consolidation', 'Pleural Effusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New approach: use 1 as positive and everything else and negative\n",
    "\n",
    "u_one_features = []\n",
    "u_zero_features = chexnet_targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_u_one_features(df: pd.DataFrame, column: str):\n",
    "    return np.where((df[column] == 1) | (df[column] == -1), 1, 0)\n",
    "\n",
    "def label_u_zero_features(df: pd.DataFrame, column: str):\n",
    "    return np.where(df[column] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df['valid'] = False\n",
    "valid_labels_df['valid'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df['patient'] = train_labels_df.Path.str.split('/',3,True)[2]\n",
    "train_labels_df  ['study'] = train_labels_df.Path.str.split('/',4,True)[3]\n",
    "\n",
    "valid_labels_df['patient'] = valid_labels_df.Path.str.split('/',3,True)[2]\n",
    "valid_labels_df  ['study'] = valid_labels_df.Path.str.split('/',4,True)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_labels_df, valid_labels_df])\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_string(row):\n",
    "    feature_list = []\n",
    "    for feature in u_one_features:\n",
    "        if row[feature] in [-1,1]:\n",
    "            feature_list.append(feature)\n",
    "            \n",
    "    for feature in u_zero_features:\n",
    "        if row[feature] == 1:\n",
    "            feature_list.append(feature)\n",
    "            \n",
    "    return ';'.join(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['feature_string'] = full_df.apply(feature_string,axis = 1).fillna('')\n",
    "full_df['feature_string'] = full_df['feature_string'].apply(lambda x:x.split(\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in u_one_features:\n",
    "    full_df[f'{col}_u_one'] = label_u_one_features(df=full_df, column=col)\n",
    "for col in u_zero_features:\n",
    "    full_df[f'{col}_u_zero'] = label_u_zero_features(df=full_df, column=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['path'] = '/data/' + full_df['Path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old targets\n",
    "# targets = ['Atelectasis_u_one', 'Edema_u_one', 'Cardiomegaly_u_zero', 'Consolidation_u_zero', 'Pleural Effusion_u_zero']\n",
    "\n",
    "# New targets\n",
    "targets = [target + '_u_zero' for target in u_zero_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = full_df['path'][~full_df['valid']].values\n",
    "y_train = full_df[targets][~full_df['valid']].values\n",
    "X_val = full_df['path'][full_df['valid']].values\n",
    "y_val = full_df[targets][full_df['valid']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the first 5 images\n",
    "paths =  full_df.path[:5]\n",
    "labels = full_df.feature_string[:5]\n",
    "\n",
    "fig, m_axs = plt.subplots(1, len(labels), figsize = (20, 10))\n",
    "#show the images and label them\n",
    "for ii, c_ax in enumerate(m_axs):\n",
    "    c_ax.imshow(np.asarray(Image.open(paths[ii])), cmap='gray')\n",
    "    c_ax.set_title(labels[ii])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = np.asarray(Image.open(X_val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.stack((img,)*3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "ax.imshow(img)\n",
    "ax.axis('off')\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_mask(image, size=12, n_squares=1):\n",
    "    h, w, channels = image.shape\n",
    "    new_image = np.asarray(image.copy())\n",
    "    for _ in range(n_squares):\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "        y1 = np.clip(y - size // 2, 0, h)\n",
    "        y2 = np.clip(y + size // 2, 0, h)\n",
    "        x1 = np.clip(x - size // 2, 0, w)\n",
    "        x2 = np.clip(x + size // 2, 0, w)\n",
    "        new_image[y1:y2, x1:x2, :] = 0\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if np.random.uniform() < 0.5:\n",
    "    augmented = apply_mask(img, size=np.random.randint(low=70, high=240), n_squares=np.random.randint(low=2, high=12))\n",
    "else:\n",
    "    augmented = tf.image.random_brightness(img, max_delta=0.2)\n",
    "    augmented = tf.image.random_saturation(image=augmented, lower=0.8, upper=1.2)\n",
    "    augmented = tf.image.random_hue(image=augmented, max_delta=0.03)\n",
    "    augmented = tf.image.random_contrast(image=augmented, lower=0.8, upper=1.2)\n",
    "# augmented = tf.image.random_flip_up_down(img)\n",
    "# augmented = tf.image.random_flip_left_right(img)\n",
    "# augmented = tf.image.random_saturation(image=img, lower=0.7, upper=1.3)\n",
    "# augmented = tf.image.random_hue(image=img, max_delta=0.03)\n",
    "# augmented = tf.image.random_contrast(image=img, lower=0.7, upper=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "ax.imshow(augmented, cmap='gray')\n",
    "ax.axis('off')\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN = len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine class weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = [col_name + '_label' for col_name in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=target_columns, height=y_train.sum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = y_train.sum(axis=0)\n",
    "total_count = y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_weights = {i: total_count/class_i_count for i, class_i_count in enumerate(class_counts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_weights_sqrt = {i: np.sqrt(weight) for i, weight in enumerate(list(cls_weights.values()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_weights_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_weights_log = {i: np.log(weight) for i, weight in enumerate(list(cls_weights.values()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_weights_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_weighted = y_train * np.array(list(cls_weights.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=target_columns, height=y_train_weighted.sum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_weighted_sqrt = y_train * np.array(list(cls_weights_sqrt.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=target_columns, height=y_train_weighted_sqrt.sum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_weighted_log = y_train * np.array(list(cls_weights_log.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=target_columns, height=y_train_weighted_log.sum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_CLASS_WEIGHTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_CLASS_WEIGHTS:\n",
    "    CLASS_WEIGHTS = cls_weights_sqrt\n",
    "else:\n",
    "    CLASS_WEIGHTS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_image_to_array(path):\n",
    "    img = np.asarray(Image.open(path), dtype=np.float32)\n",
    "    img = np.stack((img,)*3, axis=-1)\n",
    "    img /= 255.\n",
    "    img = tf.image.resize_with_pad(img, target_height=TARGET_HEIGHT, target_width=TARGET_WIDTH)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_file(X_path, y):\n",
    "    \"\"\"\n",
    "    X_path: (pandas series) contains the file paths to the images\n",
    "    y: (pandas series of type int) the target label\n",
    "    \n",
    "    return a pair of numpy arrays representing (features, target)\n",
    "    \"\"\"\n",
    "    \n",
    "    X = pd.Series(X_path).apply(convert_image_to_array)\n",
    "    X = X.values\n",
    "    X = list(X)\n",
    "    X = np.array(X, dtype='float32')\n",
    "    \n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_predict(path, model):\n",
    "    x = convert_image_to_array(path=path)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data = create_model_file(X_path=X_val, y=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image.fromarray(np.uint8(255 * val_data[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data generator for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_gen(X, y, batch_size, image_size=(TARGET_HEIGHT, TARGET_WIDTH), dtype=np.float32):\n",
    "    # Get total number of samples in the data\n",
    "    n = len(X)\n",
    "    steps = n//batch_size\n",
    "    \n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, image_size[0], image_size[1], 3), dtype=dtype)\n",
    "    batch_labels = np.zeros((batch_size, num_classes), dtype=dtype)\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "    \n",
    "    # Initialize a counter\n",
    "    i = 0\n",
    "    while True:\n",
    "        np.random.shuffle(indices)\n",
    "        # Get the next batch \n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_path = X[idx]\n",
    "            label = y[idx]\n",
    "            \n",
    "            # one hot encoding\n",
    "            encoded_label = label\n",
    "            # read the image\n",
    "            img = np.asarray(Image.open(img_path), dtype=dtype)\n",
    "            img = np.stack((img,)*3, axis=-1)\n",
    "            \n",
    "            # add image augmentation\n",
    "            if np.random.uniform() < 0.65:\n",
    "                img = apply_mask(img, size=np.random.randint(low=70, high=240), n_squares=np.random.randint(low=2, high=12))\n",
    "            else:\n",
    "                if np.random.uniform() < 0.15:\n",
    "                    img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "    #             if np.random.uniform() < 0.15:\n",
    "    #                 img = tf.image.random_flip_up_down(img)\n",
    "    #             if np.random.uniform() < 0.15:\n",
    "    #                 img = tf.image.random_flip_left_right(img)\n",
    "                if np.random.uniform() < 0.15:\n",
    "                    img = tf.image.random_saturation(image=img, lower=0.8, upper=1.2)\n",
    "                if np.random.uniform() < 0.15:\n",
    "                    img = tf.image.random_hue(image=img, max_delta=0.03)\n",
    "                if np.random.uniform() < 0.15:\n",
    "                    img = tf.image.random_contrast(image=img, lower=0.8, upper=1.2)\n",
    "            \n",
    "            img = img/255.\n",
    "            \n",
    "            # resize image\n",
    "            img = tf.image.resize_with_pad(img, target_height=image_size[0], target_width=image_size[1])\n",
    "            \n",
    "            batch_data[count] = img\n",
    "            batch_labels[count] = encoded_label\n",
    "\n",
    "            count+=1\n",
    "\n",
    "            if count==batch_size:\n",
    "                break\n",
    "            \n",
    "        i+=1\n",
    "        yield batch_data, batch_labels\n",
    "            \n",
    "        if i>=steps:\n",
    "            i=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Utility Functions\n",
    "\n",
    "Define some functions that will help simplify the fine-tuning pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def freeze_layers(model, freeze_layer_name):\n",
    "    for layer in model.layers:\n",
    "        if layer.name != freeze_layer_name:\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "            break\n",
    "            \n",
    "def unfreeze_batch_norm(model):\n",
    "    for layer in model.layers:\n",
    "        if layer.__class__.__name__ == 'BatchNormalization':\n",
    "            layer.trainable = True\n",
    "            \n",
    "def unfreeze_layer_norm(model):\n",
    "    for layer in model.layers:\n",
    "        if layer.__class__.__name__ == 'LayerNormalization':\n",
    "            layer.trainable = True\n",
    "\n",
    "def print_layer_trainable(model):\n",
    "    for layer in model.layers:\n",
    "        print('{0}:\\t{1}'.format(layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "TODO Add in MobileNetV2, EfficientNet (this requires tensorflow 2.2 nightly update import once this is in stable release), DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.xception import Xception\n",
    "\n",
    "# input_tensor = layers.Input(shape=(450, 600, 3), name='ImageInput')\n",
    "\n",
    "# model = Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: Expected input from B5, B6, B7 are 456x456, 528x528, 600x600\n",
    "# from tensorflow.python.keras.applications.efficientnet import EfficientNetB6\n",
    "\n",
    "# input_tensor = layers.Input(shape=(TARGET_HEIGHT, TARGET_WIDTH, 3), name='ImageInput')\n",
    "\n",
    "# model = EfficientNetB6(include_top=False, weights='imagenet', input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n",
    "\n",
    "# input_tensor = layers.Input(shape=(TARGET_HEIGHT, TARGET_WIDTH, 3), name='ImageInput')\n",
    "\n",
    "# model = ResNet101V2(include_top=False, weights='imagenet', input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.densenet import DenseNet201\n",
    "\n",
    "# input_tensor = layers.Input(shape=(TARGET_HEIGHT, TARGET_WIDTH, 3), name='ImageInput')\n",
    "\n",
    "# model = DenseNet201(include_top=False, weights='imagenet', input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import ConvNeXtSmall\n",
    "\n",
    "# input_tensor = layers.Input(shape=(TARGET_HEIGHT, TARGET_WIDTH, 3), name='ImageInput')\n",
    "\n",
    "# model = ConvNeXtSmall(include_top=False, weights='imagenet', input_tensor=input_tensor, include_preprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import ConvNeXtBase\n",
    "\n",
    "# input_tensor = layers.Input(shape=(TARGET_HEIGHT, TARGET_WIDTH, 3), name='ImageInput')\n",
    "\n",
    "# model = ConvNeXtBase(include_top=False, weights='imagenet', input_tensor=input_tensor, include_preprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model (alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path='./serialized_models/pretrain_model_ConvNeXtBase_w_ClssWgt_01-0.3887.h5'\n",
    "model_path='./serialized_models/pretrain_model_ConvNeXtBase_w_ClssWgt_01-0.4021.h5'\n",
    "# model_path='./serialized_models/pretrain_model_ConvNeXtSmall_w_ClssWgt_03-0.5216.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.convnext import LayerScale\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={'LayerScale': LayerScale})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine where to freeze and cut off base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: these were used to train Xception\n",
    "# transfer_layer_name = 'block14_sepconv1_act'\n",
    "# freeze_layer_name = 'add_10'\n",
    "\n",
    "# transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: these were used to train EfficientNet\n",
    "# transfer_layer_name = 'block7c_add'\n",
    "# freeze_layer_name = 'block6k_add'\n",
    "\n",
    "# transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: these were used to train ResNet101V2\n",
    "# transfer_layer_name = 'post_relu'\n",
    "# freeze_layer_name = 'conv5_block1_out'\n",
    "\n",
    "# transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: these were used to train DenseNet201\n",
    "# transfer_layer_name = 'relu'\n",
    "# # freeze_layer_name = 'conv5_block27_concat'\n",
    "\n",
    "# transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Note: these were used to train ConvNeXtSmall\n",
    "# transfer_layer_name = 'layer_normalization'\n",
    "# freeze_layer_name = 'tf.__operators__.add_33'\n",
    "\n",
    "# transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Note: these were used to train ConvNeXtBase\n",
    "transfer_layer_name = 'layer_normalization'\n",
    "# freeze_layer_name = 'tf.__operators__.add_21' # tf.__operators__.add_17, tf.__operators__.add_21, tf.__operators__.add_26, tf.__operators__.add_31\n",
    "# consider using smaller input image 512 x 512 and retrain more \n",
    "transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_model = tf.keras.Model(inputs=model.input, outputs=transfer_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(base_model, num_classes, pooling='avg', final_conv_layer='vgg_separable', expand_model=True, dropout_rate=0):\n",
    "    # Get the output of the base model on which we will build\n",
    "    x = base_model.layers[-1].output\n",
    "    \n",
    "    if expand_model:\n",
    "        if final_conv_layer == 'xception':\n",
    "            x = layers.SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_sepconv2')(x)\n",
    "            x = layers.BatchNormalization(name='block14_sepconv2_bn')(x)\n",
    "            x = layers.Activation('relu', name='block14_sepconv2_act')(x)\n",
    "        elif final_conv_layer == 'non_separable':\n",
    "            x = layers.Conv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_conv2')(x)\n",
    "            x = layers.BatchNormalization(name='block14_conv2_bn')(x)\n",
    "            x = layers.Activation('relu', name='block14_conv2_act')(x)\n",
    "        elif final_conv_layer == 'vgg_separable':\n",
    "            x = layers.SeparableConv2D(2048, (3,3), activation='relu', padding='same', name='block14_sepconv2')(x)\n",
    "        elif final_conv_layer == 'vgg':\n",
    "            x = layers.Conv2D(2048, (3,3), activation='relu', padding='same', name='block14_sepconv2')(x)\n",
    "        else:\n",
    "            raise ValueError('`final_conv_layer` should be one of the following: xception, non_separable, vgg_separable, or vgg')\n",
    "\n",
    "    if pooling == 'global_avg':\n",
    "        x = layers.GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    elif pooling == 'global_max':\n",
    "        x = layers.GlobalMaxPooling2D(name='global_max_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = layers.MaxPooling2D((2,2), name='local_max_pool')(x)\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "    elif pooling == 'avg':\n",
    "        x = layers.AveragePooling2D((2,2), name='local_avg_pool')(x)\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "    else:\n",
    "        pass\n",
    "    x = keras.layers.Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x = layers.Dense(num_classes, activation='sigmoid', name='prediction')(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = tf.keras.Model(base_model.input, x, name='Xception')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine good starting learning rate\n",
    "\n",
    "Experiment with the proper learning rate range by starting at a low number, see how many epochs for loss to get to a certain value, incrementally increase until the learning rate is too high. Use this range to determine the initial learning rate.\n",
    "\n",
    "Create a function to do this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_learning_rate(X, y, batch_size: int, lr_list: List[float], steps: int):\n",
    "    train_loss_by_lr = []\n",
    "    \n",
    "    for i, lr in enumerate(lr_list):\n",
    "        print(f'Learning rate {i + 1} of {len(lr_list)}. LR value: {lr}')\n",
    "        local_model = ConvNeXtBase(include_top=False, weights='imagenet', input_tensor=input_tensor, include_preprocessing=False)\n",
    "        local_conv_model = tf.keras.Model(inputs=local_model.input, outputs=local_model.output)\n",
    "        \n",
    "        model_lr = build_model(base_model=local_conv_model, num_classes=num_classes, dropout_rate=0.3)\n",
    "        \n",
    "        model_lr.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        \n",
    "        hist = model_lr.fit(\n",
    "            x=data_gen(X=X, y=y, batch_size=batch_size), \n",
    "            epochs=1, \n",
    "            steps_per_epoch=steps,\n",
    "            class_weight=CLASS_WEIGHTS,\n",
    "        )\n",
    "        \n",
    "        final_loss = hist.history['loss'][-1]\n",
    "        final_acc = hist.history['accuracy'][-1]\n",
    "        \n",
    "        train_loss_by_lr.append((lr, final_loss, final_acc))\n",
    "      \n",
    "    losses_df = pd.DataFrame(train_loss_by_lr, columns=['learning_rate', 'training_loss', 'training_accuracy'])\n",
    "    \n",
    "    return losses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_loss_df = determine_learning_rate(X=X_train, \n",
    "#                                      y=y_train, \n",
    "#                                      batch_size=2, \n",
    "#                                      lr_list=[1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6, 1e-6, 1e-7, 1e-8,],\n",
    "#                                      steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(x=lr_loss_df['learning_rate'].values, y=lr_loss_df['training_loss'].values)\n",
    "# plt.xscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ideally retrain the entire model, but memory is constrained \n",
    "# freeze_layers(conv_model, freeze_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_model(base_model=conv_model, num_classes=num_classes, dropout_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unfreeze_batch_norm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unfreeze_layer_norm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_layer_trainable(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.CosineDecayRestarts(\n",
    "      # initial_learning_rate=3e-3, # for uniform weighting\n",
    "      initial_learning_rate=3e-4, # for sqrt weighting \n",
    "      first_decay_steps=7979)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through cosine decay with restarts 7 times per epoch\n",
    "7979 == 55853 / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 4\n",
    "model_path='./serialized_models/pretrain_model_ConvNeXtBase_w_ClssWgt_{epoch:02d}-{val_loss:.4f}.h5'\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=model_path, save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    x=data_gen(X=X_train, y=y_train, batch_size=batch_size), \n",
    "    epochs=epochs, \n",
    "    callbacks=callbacks, \n",
    "    validation_data=val_data, \n",
    "    steps_per_epoch=int(NUM_TRAIN/batch_size),\n",
    "    class_weight=CLASS_WEIGHTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13300/55853, loss: 0.3006, accuracy: 0.2011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save final model - Make sure name is correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('./serialized_models/pretrain_model_ConvNeXtBase_w_ClssWgt_04-0.4061.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance\n",
    "\n",
    "### TODO\n",
    "- Move all these utility function to a python script instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load specific model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.convnext import LayerScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./serialized_models/pretrain_model_ConvNeXtBase_w_ClssWgt_01-0.3616.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_path, custom_objects={'LayerScale': LayerScale})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'pretrain_model_ConvNeXtBase_w_ClssWgt_01-0.3616.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_columns = [col_name + '_pred' for col_name in targets]\n",
    "target_columns = [col_name + '_label' for col_name in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_preds = pd.DataFrame(0, index=np.arange(len(X_val)), columns=pred_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, path in enumerate(X_val):\n",
    "    all_model_preds.iloc[i, :] = model_predict(path=path, model=model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=y_val, columns=target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([results, all_model_preds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = results[target_columns].values\n",
    "pred = results[pred_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(x = target_columns, height= y.sum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positives(y, pred, th=0.5):\n",
    "    \"\"\"\n",
    "    Count true positives.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): ground truth, size (n_examples)\n",
    "        pred (np.array): model output, size (n_examples)\n",
    "        th (float): cutoff value for positive prediction from model\n",
    "    Returns:\n",
    "        TP (int): true positives\n",
    "    \"\"\"\n",
    "    TP = 0\n",
    "    \n",
    "    # get thresholded predictions\n",
    "    thresholded_preds = pred >= th\n",
    "\n",
    "    # compute TP\n",
    "    TP = np.sum((y == 1) & (thresholded_preds == 1))\n",
    "    \n",
    "    return TP\n",
    "\n",
    "def true_negatives(y, pred, th=0.5):\n",
    "    \"\"\"\n",
    "    Count true negatives.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): ground truth, size (n_examples)\n",
    "        pred (np.array): model output, size (n_examples)\n",
    "        th (float): cutoff value for positive prediction from model\n",
    "    Returns:\n",
    "        TN (int): true negatives\n",
    "    \"\"\"\n",
    "    TN = 0\n",
    "    \n",
    "    # get thresholded predictions\n",
    "    thresholded_preds = pred >= th\n",
    "    \n",
    "    # compute TN\n",
    "    TN = np.sum((y == 0) & (thresholded_preds == 0))\n",
    "    \n",
    "    return TN\n",
    "\n",
    "def false_positives(y, pred, th=0.5):\n",
    "    \"\"\"\n",
    "    Count false positives.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): ground truth, size (n_examples)\n",
    "        pred (np.array): model output, size (n_examples)\n",
    "        th (float): cutoff value for positive prediction from model\n",
    "    Returns:\n",
    "        FP (int): false positives\n",
    "    \"\"\"\n",
    "    FP = 0\n",
    "    \n",
    "    # get thresholded predictions\n",
    "    thresholded_preds = pred >= th\n",
    "\n",
    "    # compute FP\n",
    "    FP = np.sum((y == 0) & (thresholded_preds == 1))\n",
    "    \n",
    "    return FP\n",
    "\n",
    "def false_negatives(y, pred, th=0.5):\n",
    "    \"\"\"\n",
    "    Count false positives.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): ground truth, size (n_examples)\n",
    "        pred (np.array): model output, size (n_examples)\n",
    "        th (float): cutoff value for positive prediction from model\n",
    "    Returns:\n",
    "        FN (int): false negatives\n",
    "    \"\"\"\n",
    "    FN = 0\n",
    "    \n",
    "    # get thresholded predictions\n",
    "    thresholded_preds = pred >= th\n",
    "    \n",
    "    # compute FN\n",
    "    FN = np.sum((y == 1) & (thresholded_preds == 0))\n",
    "    \n",
    "    return FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "\n",
    "def get_true_pos(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == True) & (y == 1))\n",
    "\n",
    "\n",
    "def get_true_neg(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == False) & (y == 0))\n",
    "\n",
    "\n",
    "def get_false_neg(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == False) & (y == 1))\n",
    "\n",
    "\n",
    "def get_false_pos(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == True) & (y == 0))\n",
    "\n",
    "\n",
    "def get_performance_metrics(y, pred, class_labels, tp=get_true_pos,\n",
    "                            tn=get_true_neg, fp=get_false_pos,\n",
    "                            fn=get_false_neg,\n",
    "                            acc=None, prevalence=None, spec=None,\n",
    "                            sens=None, ppv=None, npv=None, auc=None, f1=None,\n",
    "                            thresholds=[]):\n",
    "    if len(thresholds) != len(class_labels):\n",
    "        thresholds = [.5] * len(class_labels)\n",
    "\n",
    "    columns = [\"\", \"TP\", \"TN\", \"FP\", \"FN\", \"Accuracy\", \"Prevalence\",\n",
    "               \"Sensitivity\",\n",
    "               \"Specificity\", \"PPV\", \"NPV\", \"AUC\", \"F1\", \"Threshold\"]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for i in range(len(class_labels)):\n",
    "        df.loc[i] = [\"\"] + [0] * (len(columns) - 1)\n",
    "        df.iloc[i, 0] = class_labels[i]\n",
    "        df.iloc[i, 1] = round(tp(y[:, i], pred[:, i]),\n",
    "                             3) if tp != None else \"Not Defined\"\n",
    "        df.iloc[i, 2] = round(tn(y[:, i], pred[:, i]),\n",
    "                             3) if tn != None else \"Not Defined\"\n",
    "        df.iloc[i, 3] = round(fp(y[:, i], pred[:, i]),\n",
    "                             3) if fp != None else \"Not Defined\"\n",
    "        df.iloc[i, 4] = round(fn(y[:, i], pred[:, i]),\n",
    "                             3) if fn != None else \"Not Defined\"\n",
    "        df.iloc[i, 5] = round(acc(y[:, i], pred[:, i], thresholds[i]),\n",
    "                             3) if acc != None else \"Not Defined\"\n",
    "        df.iloc[i, 6] = round(prevalence(y[:, i]),\n",
    "                             3) if prevalence != None else \"Not Defined\"\n",
    "        df.iloc[i, 7] = round(sens(y[:, i], pred[:, i], thresholds[i]),\n",
    "                             3) if sens != None else \"Not Defined\"\n",
    "        df.iloc[i, 8] = round(spec(y[:, i], pred[:, i], thresholds[i]),\n",
    "                             3) if spec != None else \"Not Defined\"\n",
    "        df.iloc[i, 9] = round(ppv(y[:, i], pred[:, i], thresholds[i]),\n",
    "                             3) if ppv != None else \"Not Defined\"\n",
    "        df.iloc[i, 10] = round(npv(y[:, i], pred[:, i], thresholds[i]),\n",
    "                              3) if npv != None else \"Not Defined\"\n",
    "        try:\n",
    "            df.iloc[i, 11] = round(auc(y[:, i], pred[:, i]),\n",
    "                                  3) if auc != None else \"Not Defined\"\n",
    "        except:\n",
    "            df.iloc[i, 11] = np.NAN\n",
    "        df.iloc[i, 12] = round(f1(y[:, i], pred[:, i] > thresholds[i]),\n",
    "                              3) if f1 != None else \"Not Defined\"\n",
    "        df.iloc[i, 13] = round(thresholds[i], 3)\n",
    "\n",
    "    df = df.set_index(\"\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_confidence_intervals(class_labels, statistics):\n",
    "    df = pd.DataFrame(columns=[\"Mean AUC (CI 5%-95%)\"])\n",
    "    for i in range(len(class_labels)):\n",
    "        mean = statistics.mean(axis=1)[i]\n",
    "        max_ = np.quantile(statistics, .95, axis=1)[i]\n",
    "        min_ = np.quantile(statistics, .05, axis=1)[i]\n",
    "        df.loc[class_labels[i]] = [\"%.2f (%.2f-%.2f)\" % (mean, min_, max_)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_curve(gt, pred, target_names, curve='roc'):\n",
    "    for i in range(len(target_names)):\n",
    "        if curve == 'roc':\n",
    "            curve_function = roc_curve\n",
    "            auc_roc = roc_auc_score(gt[:, i], pred[:, i])\n",
    "            label = target_names[i] + \" AUC: %.3f \" % auc_roc\n",
    "            xlabel = \"False positive rate\"\n",
    "            ylabel = \"True positive rate\"\n",
    "            a, b, _ = curve_function(gt[:, i], pred[:, i])\n",
    "            plt.figure(1, figsize=(7, 7))\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.plot(a, b, label=label)\n",
    "            plt.xlabel(xlabel)\n",
    "            plt.ylabel(ylabel)\n",
    "\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
    "                       fancybox=True, ncol=1)\n",
    "        elif curve == 'prc':\n",
    "            precision, recall, _ = precision_recall_curve(gt[:, i], pred[:, i])\n",
    "            average_precision = average_precision_score(gt[:, i], pred[:, i])\n",
    "            label = target_names[i] + \" Avg.: %.3f \" % average_precision\n",
    "            plt.figure(1, figsize=(7, 7))\n",
    "            plt.step(recall, precision, where='post', label=label)\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
    "                       fancybox=True, ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_performance_metrics(y, pred, target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y, pred, th=0.5):\n",
    "    \"\"\"\n",
    "    Compute accuracy of predictions at threshold.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): ground truth, size (n_examples)\n",
    "        pred (np.array): model output, size (n_examples)\n",
    "        th (float): cutoff value for positive prediction from model\n",
    "    Returns:\n",
    "        accuracy (float): accuracy of predictions at threshold\n",
    "    \"\"\"\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    # get TP, FP, TN, FN using our previously defined functions\n",
    "    TP = true_positives(y, pred, th)\n",
    "    FP = false_positives(y, pred, th)\n",
    "    TN = true_negatives(y, pred, th)\n",
    "    FN = false_negatives(y, pred, th)\n",
    "\n",
    "    # Compute accuracy using TP, FP, TN, FN\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_performance_metrics(y, pred, target_columns, acc=get_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prevalence(y):\n",
    "    \"\"\"\n",
    "    Compute accuracy of predictions at threshold.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): ground truth, size (n_examples)\n",
    "    Returns:\n",
    "        prevalence (float): prevalence of positive cases\n",
    "    \"\"\"\n",
    "    prevalence = 0.0\n",
    "    \n",
    "    prevalence = np.sum(y) / len(y)\n",
    "    \n",
    "    return prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_performance_metrics(y, pred, target_columns, acc=get_accuracy, prevalence=get_prevalence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensitivity(y, pred, th=0.5):\n",
    "    \"\"\"\n",
    "    Compute sensitivity of predictions at threshold.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): ground truth, size (n_examples)\n",
    "        pred (np.array): model output, size (n_examples)\n",
    "        th (float): cutoff value for positive prediction from model\n",
    "    Returns:\n",
    "        sensitivity (float): probability that our test outputs positive given that the case is actually positive\n",
    "    \"\"\"\n",
    "    sensitivity = 0.0\n",
    "    \n",
    "    # get TP and FN using our previously defined functions\n",
    "    TP = true_positives(y, pred, th)\n",
    "    FN = false_negatives(y, pred, th)\n",
    "\n",
    "    # use TP and FN to compute sensitivity\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    \n",
    "    return sensitivity\n",
    "\n",
    "def get_specificity(y, pred, th=0.5):\n",
    "    \"\"\"\n",
    "    Compute specificity of predictions at threshold.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): ground truth, size (n_examples)\n",
    "        pred (np.array): model output, size (n_examples)\n",
    "        th (float): cutoff value for positive prediction from model\n",
    "    Returns:\n",
    "        specificity (float): probability that the test outputs negative given that the case is actually negative\n",
    "    \"\"\"\n",
    "    specificity = 0.0\n",
    "    \n",
    "    # get TN and FP using our previously defined functions\n",
    "    TN = true_negatives(y, pred, th)\n",
    "    FP = false_positives(y, pred, th)\n",
    "    \n",
    "    # use TN and FP to compute specificity \n",
    "    specificity = TN / (TN + FP)\n",
    "    \n",
    "    return specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_performance_metrics(y, pred, target_columns, acc=get_accuracy, prevalence=get_prevalence, sens=get_sensitivity, spec=get_specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppv(y, pred, th=0.5):\n",
    "    \"\"\"\n",
    "    Compute PPV of predictions at threshold.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): ground truth, size (n_examples)\n",
    "        pred (np.array): model output, size (n_examples)\n",
    "        th (float): cutoff value for positive prediction from model\n",
    "    Returns:\n",
    "        PPV (float): positive predictive value of predictions at threshold\n",
    "    \"\"\"\n",
    "    PPV = 0.0\n",
    "    \n",
    "    # get TP and FP using our previously defined functions\n",
    "    TP = true_positives(y, pred, th)\n",
    "    FP = false_positives(y, pred, th)\n",
    "\n",
    "    # use TP and FP to compute PPV\n",
    "    PPV = TP / (TP + FP)\n",
    "    \n",
    "    return PPV\n",
    "\n",
    "def get_npv(y, pred, th=0.5):\n",
    "    \"\"\"\n",
    "    Compute NPV of predictions at threshold.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): ground truth, size (n_examples)\n",
    "        pred (np.array): model output, size (n_examples)\n",
    "        th (float): cutoff value for positive prediction from model\n",
    "    Returns:\n",
    "        NPV (float): negative predictive value of predictions at threshold\n",
    "    \"\"\"\n",
    "    NPV = 0.0\n",
    "    \n",
    "    # get TN and FN using our previously defined functions\n",
    "    TN = true_negatives(y, pred, th)\n",
    "    FN = false_negatives(y, pred, th)\n",
    "\n",
    "    # use TN and FN to compute NPV\n",
    "    NPV = TN / (TN + FN)\n",
    "    \n",
    "    return NPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_performance_metrics(y, pred, target_columns, acc=get_accuracy, prevalence=get_prevalence, sens=get_sensitivity, spec=get_specificity, ppv=get_ppv, npv=get_npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_curve(y, pred, target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "get_performance_metrics(y, pred, target_columns, acc=get_accuracy, prevalence=get_prevalence, \n",
    "                        sens=get_sensitivity, spec=get_specificity, ppv=get_ppv, npv=get_npv, auc=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_auc(y, pred, classes, bootstraps = 100, fold_size = 1000):\n",
    "    statistics = np.zeros((len(classes), bootstraps))\n",
    "\n",
    "    for c in range(len(classes)):\n",
    "        df = pd.DataFrame(columns=['y', 'pred'])\n",
    "        df.loc[:, 'y'] = y[:, c]\n",
    "        df.loc[:, 'pred'] = pred[:, c]\n",
    "        # get positive examples for stratified sampling\n",
    "        df_pos = df[df.y == 1]\n",
    "        df_neg = df[df.y == 0]\n",
    "        prevalence = len(df_pos) / len(df)\n",
    "        for i in range(bootstraps):\n",
    "            # stratified sampling of positive and negative examples\n",
    "            pos_sample = df_pos.sample(n = int(fold_size * prevalence), replace=True)\n",
    "            neg_sample = df_neg.sample(n = int(fold_size * (1-prevalence)), replace=True)\n",
    "\n",
    "            y_sample = np.concatenate([pos_sample.y.values, neg_sample.y.values])\n",
    "            pred_sample = np.concatenate([pos_sample.pred.values, neg_sample.pred.values])\n",
    "            try:\n",
    "                score = roc_auc_score(y_sample, pred_sample)\n",
    "            except:\n",
    "                score = 0\n",
    "            statistics[c][i] = score\n",
    "    return statistics\n",
    "\n",
    "statistics = bootstrap_auc(y, pred, target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confidence_intervals(target_columns, statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "def plot_calibration_curve(y, pred):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(len(target_columns)):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        fraction_of_positives, mean_predicted_value = calibration_curve(y[:,i], pred[:,i], n_bins=20)\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        plt.plot(mean_predicted_value, fraction_of_positives, marker='.')\n",
    "        plt.xlabel(\"Predicted Value\")\n",
    "        plt.ylabel(\"Fraction of Positives\")\n",
    "        plt.title(target_columns[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "model_performance_df = get_performance_metrics(y, pred, target_columns, acc=get_accuracy, prevalence=get_prevalence, \n",
    "                        sens=get_sensitivity, spec=get_specificity, ppv=get_ppv, npv=get_npv, auc=roc_auc_score,f1=f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df.to_csv(f'model_performance/test_metrics_{MODEL_NAME}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confidence_intervals(target_columns, statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Grad-CAM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MY_IMG_PATH = X_test[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MY_IMG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DenseNet201, Xception\n",
    "last_conv_layer_name = 'block14_sepconv2'\n",
    "classifier_layer_names = ['local_avg_pool', 'flatten', 'prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_num = 9\n",
    "\n",
    "X_test_example = X_test[test_num]\n",
    "y_test_example = y_test[test_num]\n",
    "\n",
    "y_hat = model_predict(path=X_test_example, model=model)\n",
    "\n",
    "print(f'Ground truth label: {y_test_example} \\n Predicted label: {np.argmax(y_hat)} \\t Probability: {np.max(y_hat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model on the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = create_model_file(X_path=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(x=test_data[0], y=test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # EfficientNetV2S\n",
    "# last_conv_layer_name = 'top_conv'\n",
    "# classifier_layer_names = ['top_bn', 'top_activation', 'local_avg_pool', 'flatten', 'prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img_array(img_path):\n",
    "    img = convert_image_to_array(path=img_path)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    # Second, we create a model that maps the activations of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = keras.Model(classifier_input, x)\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        # Compute class predictions\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "\n",
    "    # This is the gradient of the top predicted class with regard to\n",
    "    # the output feature map of the last conv layer\n",
    "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First look at active regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare image\n",
    "img_array = get_img_array(img_path=MY_IMG_PATH)\n",
    "\n",
    "# Print what the top predicted class is\n",
    "preds = model.predict(img_array)\n",
    "pred_class = np.argmax(preds)\n",
    "pred_label = 'normal' if pred_class == 0 else 'nodule'\n",
    "pred_prob = np.max(preds)\n",
    "#print(f\"Predicted class: {pred_label} \\n Probability: {pred_prob} \\n Actual Class: {lesion_type_dict[label_abbreviation]}\")\n",
    "print(f\"Predicted class: {pred_label} \\n Probability: {pred_prob}\")\n",
    "\n",
    "# Generate class activation heatmap\n",
    "heatmap = make_gradcam_heatmap(\n",
    "    img_array, model, last_conv_layer_name, classifier_layer_names\n",
    ")\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlay the heatmap on the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We load the original image\n",
    "#img = np.asarray(Image.open(SAMPLE_PATH))\n",
    "img = convert_image_to_array(path=MY_IMG_PATH)\n",
    "# img = np.expand_dims(img, axis=0)\n",
    "# img = img.squeeze()\n",
    "img = np.uint8(255. * img)\n",
    "# img = np.uint8(img)\n",
    "\n",
    "# We rescale heatmap to a range 0-255\n",
    "heatmap = np.uint8(255. * heatmap)\n",
    "\n",
    "# We use jet colormap to colorize heatmap\n",
    "jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "# We use RGB values of the colormap\n",
    "jet_colors = jet(np.arange(256))[:, :3]\n",
    "jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "# We create an image with RGB colorized heatmap\n",
    "jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "# Superimpose the heatmap on original image\n",
    "superimposed_img = jet_heatmap * 0.2 + img\n",
    "superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "# Save the superimposed image\n",
    "save_path = \"heatmap.jpg\"\n",
    "superimposed_img.save(save_path)\n",
    "\n",
    "# Display Grad CAM along with original image\n",
    "fig, axs = plt.subplots(1, 2, figsize = (10, 5))\n",
    "\n",
    "axs[0].imshow(np.asarray(Image.open(save_path)))\n",
    "axs[0].axis('off')\n",
    "axs[0].set_aspect('auto')\n",
    "#axs[1].imshow(np.asarray(Image.open(SAMPLE_PATH)))\n",
    "# axs[1].imshow(np.asarray(Image.open(MY_IMG_PATH)))\n",
    "axs[1].imshow(np.asarray(img))\n",
    "axs[1].axis('off')\n",
    "axs[1].set_aspect('auto')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
